{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A4: LSTMs and Transformers for Word Sense Disambiguation\n",
    "\n",
    "by Nikolai Ilinykh, Adam Ek, and others.\n",
    "\n",
    "The lab is an exploration and learning exercise to be done in a group and also in discussion with the teachers and other students.\n",
    "\n",
    "Write all your answers and the code in the appropriate boxes below.\n",
    "\n",
    "\n",
    "A problem with static distributional vectors is the difficulty of distinguishing between different *word senses*. We will continue our exploration of word vectors by considering *trainable vectors* or *word embeddings* for Word Sense Disambiguation (WSD). We will work with both LSTMs and transformer models, e.g. BERT. The purpose of the assignment is to learn use representations neural models in a downstream task of word sense disambiguation.\n",
    "\n",
    "\n",
    "## Word Sense Disambiguation Task\n",
    "\n",
    "The goal of word sense disambiguation is to train a model to find the sense of a word (homonyms of a word-form). For example, the word \"bank\" can mean \"sloping land\" or \"financial institution\". \n",
    "\n",
    "(a) \"I deposited my money in the **bank**\" (financial institution)\n",
    "\n",
    "(b) \"I swam from the river **bank**\" (sloping land)\n",
    "\n",
    "In case a) and b), we can determine the meaning of \"bank\" based on the *context*. To utilize context in a semantic model, we use *contextualized word representations*.\n",
    "\n",
    "Previously, we worked with *static word representations*, i.e., the representation does not depend on the context. To illustrate, we can consider sentences (a) and (b), where the word **bank** would have the same static representation in both sentences, which means that it becomes difficult for us to predict its sense. What we want is to create representations that depend on the context, i.e., *contextualized embeddings*.\n",
    "\n",
    "As we have discussed in the class, contextualized representations can come in the form of pre-training the model for some \"general\" task and then fine-tuning it for some downstream task. Here we will do the following:\n",
    "\n",
    "(1) Train and test LSTM model directly for word sense disambiguation. We will learn contextualized representations within this model.\n",
    "\n",
    "(2) Take BERT that was pre-trained on masked language modeling and next sentence prediction. Fine-tune it on our data and test it for the word sense disambiguation on the task dataset. The idea for you is to explore how pre-trained contextualized representations from BERT can be updated and used for the downstream task of word sense disambiguation.\n",
    "\n",
    "Your overall task in this lab is to create a neural network model that can disambiguate the word sense of 30 different words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we import some packages that we need\n",
    "\n",
    "# here add any package that you will need later\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#import spacy #tokenize by craft, or `tokenizer = spacy.load(\"en_core_web_sm\")`(cost more time...)\n",
    "#import torchtext # User warning: Torchtext is deprecated\n",
    "#from torchtext.data import get_tokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import defaultdict\n",
    "\n",
    "# our hyperparameters (add more when/if you need them)\n",
    "device = torch.device('cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install spacy # install necessary packages before import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Working with Data\n",
    "\n",
    "A central part of any machine learning system is the data we're working with.\n",
    "\n",
    "In this section, we will split the data (the dataset is in `wsd_data.txt`) into a training set and a test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The dataset we will use contains different word senses for 30 different words. The data is organized as follows (values separated by tabs), where each line is a separate item in the dataset:\n",
    "\n",
    "- Column 1: word-sense, e.g., keep%2:42:07::\n",
    "- Column 2: word-form, e.g., keep.v\n",
    "- Column 3: index of word, e.g., 15\n",
    "- Column 4: white-space tokenized context, e.g., Action by the Committee In pursuance of its mandate , the Committee will continue to keep under review the situation relating to the question of Palestine and participate in relevant meetings of the General Assembly and the Security Council . The Committee will also continue to monitor the situation on the ground and draw the attention of the international community to urgent developments in the Occupied Palestinian Territory , including East Jerusalem , requiring international action .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Understand the data]**\n",
    "\n",
    "It is a snippet from WordNet: \n",
    "\n",
    "`word-sense`: Sense Key, lemma%pos:sense_number:lexicographer_file_number\n",
    "\n",
    "`index` represents the position of the word in the context.\n",
    "\n",
    "e.g., `S: (n) support (support%1:21:00::), keep (keep%1:21:00::), livelihood (livelihood%1:21:00::), living (living%1:21:00::), bread and butter (bread_and_butter%1:21:00::), sustenance (sustenance%1:21:00::) (the financial means whereby one lives) \"each child was expected to pay for their keep\"; \"he applied to the state for support\"; \"he could no longer earn his own livelihood\"`\n",
    "\n",
    "POS: noun(n)\n",
    "\n",
    "Sysets: support, keep, livelihood, living, bread and butter, sustenance\n",
    "\r\n",
    "Definition: the financial means wherebyone lives\n",
    "\n",
    "\r\n",
    "Example sentences: \"each child was expected to pay for their keep\"; \"he applied to the state for support\"; \"he could no longer earn his own livelihood\"\n",
    "\n",
    "ref: https://wordnet.princeton.edu/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data\n",
    "\n",
    "Your first task is to separate the data into a *training set* and a *test set*.\n",
    "\n",
    "The training set should contain 80% of the examples, and the test set the remaining 20%.\n",
    "\n",
    "The examples for the test/training set should be selected **randomly**.\n",
    "\n",
    "Save each dataset into a .csv file for loading later.\n",
    "\n",
    "**[2 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(dataset_path):\n",
    "    \"\"\"\n",
    "    Split the dataset into a training set and a test set, and save them into separate .csv files.\n",
    "\n",
    "    Parameters:\n",
    "        dataset_path (str): The file path to the dataset.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame, pd.DataFrame: A tuple containing the training set and the test set as pandas DataFrames.\n",
    "    \"\"\"\n",
    "    # Load dataset\n",
    "    data = pd.read_csv(dataset_path, sep='\\t', header=None)\n",
    "    data.columns = ['word_sense', 'word_form', 'index', 'context']\n",
    "\n",
    "    # Shuffle dataset\n",
    "    data_shuffled = data.sample(frac=1, random_state=42)\n",
    "\n",
    "    # Calculate number of examples for training and test sets\n",
    "    num_examples = len(data_shuffled)\n",
    "    train_size = int(0.8 * num_examples)\n",
    "\n",
    "    # Split dataset\n",
    "    train_split = data_shuffled.iloc[:train_size]\n",
    "    test_split = data_shuffled.iloc[train_size:]\n",
    "\n",
    "    # Save splits to CSV files\n",
    "    train_split.to_csv('train_split.csv', index=False)\n",
    "    test_split.to_csv('test_split.csv', index=False)\n",
    "    \n",
    "    return train_split, test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = data_split('wsd_data.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Baseline\n",
    "\n",
    "Your second task is to create a *baseline* for the task.\n",
    "\n",
    "A baseline is a \"reality check\" for a model. Given a very simple heuristic/algorithmic/model solution to the problem, can our neural network perform better than this? Baselines are important as they give us a point of comparison for the actual models. They are commonly used in NLP. Sometimes baseline models are not simple models but previous state-of-the-art.\n",
    "\n",
    "In this exercise, we will have a simple baseline model that is the \"most common sense\" (MCS) baseline. For each word form, find the most commonly assigned sense to the word and label a word with that sense. In a fictional dataset, \"bank\" has two senses: \"financial institution,\" which occurs 5 times, and \"side of the river,\" which occurs 3 times. Thus, all 8 occurrences of \"bank\" are labeled \"financial institution,\" yielding an MCS accuracy of 5/8 = 62.5%. If a model obtains a higher score than this, we can conclude that the model *at least* is better than selecting the most frequent word sense.\n",
    "\n",
    "Your task is to write the code for this baseline, train, and test it. The baseline has the knowledge about labels and their frequency only from the train data. You evaluate it on the test data by comparing the ground-truth sense with the one that the model predicts. A good \"dumb\" baseline in this case is the one that performs quite badly. Expect the model to perform around 0.30 in terms of accuracy. You should use accuracy as your main metric; you can also compute the F1-score.\n",
    "\n",
    "**[2 marks]**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcs_baseline(train_data, test_data):\n",
    "    \"\"\"\n",
    "    Most Common Sense (MCS) baseline for word sense disambiguation.\n",
    "\n",
    "    Parameters:\n",
    "        train_data (pd.DataFrame): The DataFrame containing the training dataset with columns: \n",
    "                                   'word_sense', 'word_form', 'index', 'context'.\n",
    "        test_data (pd.DataFrame): The DataFrame containing the test dataset with the same columns.\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy of the baseline model.\n",
    "        dict: Per-word-form accuracy (weighted).\n",
    "    \"\"\"\n",
    "    # Calculate the most common sense for each word form in the training data\n",
    "    most_common_senses = train_data.groupby('word_form')['word_sense'].agg(lambda x: x.value_counts().idxmax())\n",
    "\n",
    "    # Predict the most common sense for each example in the test data\n",
    "    predictions = test_data['word_form'].map(most_common_senses)\n",
    "\n",
    "    # Calculate overall accuracy\n",
    "    accuracy = (predictions == test_data['word_sense']).mean()\n",
    "\n",
    "    # Calculate per-word-form accuracy (weighted)\n",
    "    per_word_form_accuracy = {}\n",
    "    for word_form, predicted_sense in zip(test_data['word_form'], predictions):\n",
    "        actual_sense = test_data[test_data['word_form'] == word_form]['word_sense'].iloc[0]\n",
    "        num_senses = len(train_data[train_data['word_form'] == word_form]['word_sense'].unique())\n",
    "        per_word_form_accuracy[word_form] = {\n",
    "        'accuracy': int(predicted_sense == actual_sense) / num_senses,\n",
    "        'sense_count': num_senses\n",
    "    }\n",
    "\n",
    "    return accuracy, per_word_form_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCS baseline accuracy: 0.3193293885601578\n"
     ]
    }
   ],
   "source": [
    "baseline_accuracy, baseline_per_word_form_accuracy = mcs_baseline(train_set, test_set)\n",
    "print(\"MCS baseline accuracy:\", baseline_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Data Iterators\n",
    "\n",
    "To train a neural network, we first need to prepare the data. This involves converting words (and labels) to a number and organizing the data into batches. We also want the ability to shuffle the examples such that they appear in a random order.\n",
    "\n",
    "Your task is to create a dataloader for the training and test set you created previously.\n",
    "\n",
    "You are encouraged to adjust your own dataloader you built for previous assignments. Some things to take into account:\n",
    "\n",
    "1. Tokenize inputs, keep a dictionary of word-to-IDs and IDs-to-words (vocabulary), fix paddings. You might need to consider doing these for each of the four fields in the dataset.\n",
    "2. Your dataloader probably has a function to process data. Process each column in the dataset.\n",
    "3. You might want to clean the data a bit. For example, the first column has some symbols, which might be unnecessary. It is up to you whether you want to remove them and clean this column or keep labels the way they are. In any case, you must provide an explanation of your decision and how you think it will affect the performance of your model. Data and its preprocessing matters, so motivate your decisions.\n",
    "4. Organize your dataset into batches and shuffle them. You should have something akin to data iterators so that your model can take them.\n",
    "\n",
    "Implement the dataloader and perform necessary preprocessings.\n",
    "\n",
    "[**2 marks**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom PyTorch dataset for word sense disambiguation.\n",
    "\n",
    "    Attributes:\n",
    "        data (DataFrame): The DataFrame containing the dataset.\n",
    "        word_to_idx (dict): A dictionary mapping words to their indices.\n",
    "        label_encoder (LabelEncoder): An instance of sklearn's LabelEncoder for encoding word senses.\n",
    "        word_form_sense_counts (dict): A dictionary to track sense counts for each word form.\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): The DataFrame containing the dataset.\n",
    "        word_to_idx (dict): A dictionary mapping words to their indices.\n",
    "        label_encoder (LabelEncoder): An instance of sklearn's LabelEncoder for encoding word senses.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, word_to_idx, label_encoder):\n",
    "        self.data = data\n",
    "        # print(\"data sample:\",data.head(10))\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.label_encoder = label_encoder\n",
    "        self.word_form_sense_counts = defaultdict(set)  # Initialize as defaultdict to handle unseen word forms\n",
    "        \n",
    "        # Count senses for each word form and calculate frequencies\n",
    "        for idx in range(len(data)):\n",
    "            word_form = data.iloc[idx]['word_form']\n",
    "            word_sense = data.iloc[idx]['word_sense']\n",
    "            if word_form not in self.word_form_sense_counts:\n",
    "                self.word_form_sense_counts[word_form] = set()  # Use a set to avoid duplicates\n",
    "            self.word_form_sense_counts[word_form].add(word_sense)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Get the length of the dataset.\n",
    "\n",
    "        Returns:\n",
    "            int: The number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get a sample from the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the sample to retrieve.`idx` is passed during calling Dataloader.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the sample data with keys 'word_form', 'index', 'context', 'word_sense' and 'word_sense_counts'.\n",
    "        \"\"\"\n",
    "        row = self.data.iloc[idx] \n",
    "        \n",
    "        word_form = row['word_form']\n",
    "        index = row['index']\n",
    "        context = row['context']\n",
    "        word_sense = row['word_sense']\n",
    "        \n",
    "        # Tokenize and convert to indices\n",
    "        tokenized_context = []\n",
    "        for token in context.lower().split():\n",
    "            if token in self.word_to_idx:\n",
    "                tokenized_context.append(self.word_to_idx[token])\n",
    "            else:\n",
    "                tokenized_context.append(self.word_to_idx['<UNK>'])\n",
    "\n",
    "        target_word = word_form.split('.')[0]\n",
    "        # print(\"target_word:\",target_word)\n",
    "        # print(\"context:\",context)\n",
    "        mapped_target_word = self.word_to_idx[target_word] if target_word in self.word_to_idx else self.word_to_idx['<UNK>']\n",
    "        \n",
    "        # Encode word sense\n",
    "        encoded_word_sense = self.label_encoder.transform([word_sense])[0]\n",
    "\n",
    "        # Count number of senses for this word form\n",
    "        word_sense_counts = len(self.word_form_sense_counts[word_form])\n",
    "\n",
    "        return {\n",
    "            'word_form': mapped_target_word,\n",
    "            'index': index,\n",
    "            'context': tokenized_context,\n",
    "            'word_sense': encoded_word_sense,\n",
    "            'word_sense_counts': word_sense_counts\n",
    "        }\n",
    "\n",
    "\n",
    "def collate_batch(batch):\n",
    "    \"\"\"\n",
    "    Collate function for processing each batch in the DataLoader.\n",
    "\n",
    "    Args:\n",
    "        batch (list): A list of samples, where each sample is a dictionary containing keys 'context', 'index', 'word_form', 'word_sense' and 'word_sense_counts'.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the batch data with keys 'context', 'target_index', 'word_form', 'word_sense' and 'word_sense_counts'.\n",
    "            'context' is a padded tensor representing the contexts of the samples, 'target_index' is a tensor containing the indices of the target words, \n",
    "            'word_form' is a tensor containing the indices of the target words, 'word_sense' is a tensor containing the encoded word senses,\n",
    "            and 'word_sense_counts' is a tensor containing the number of senses for each word form.\n",
    "    \"\"\"\n",
    "    contexts = [torch.tensor(item['context'], dtype=torch.long) for item in batch]\n",
    "    word_indice = torch.tensor([item['index'] for item in batch], dtype=torch.long)\n",
    "    word_forms = torch.tensor([item['word_form'] for item in batch], dtype=torch.long)\n",
    "    word_senses = torch.tensor([item['word_sense'] for item in batch], dtype=torch.long)\n",
    "    word_sense_counts = torch.tensor([item['word_sense_counts'] for item in batch], dtype=torch.long)  # for later evaluation\n",
    "\n",
    "    contexts_padded = pad_sequence(contexts, batch_first=True, padding_value=1)\n",
    "\n",
    "    return {\n",
    "        'context': contexts_padded,\n",
    "        'target_index': word_indice,\n",
    "        'word_form': word_forms,\n",
    "        'word_sense': word_senses,\n",
    "        'word_sense_counts': word_sense_counts\n",
    "    }\n",
    "\n",
    "def build_word_to_idx(data):\n",
    "    \"\"\"\n",
    "    Build a dictionary mapping words to their corresponding indices based on the given dataset.\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): DataFrame containing the dataset, with a column named 'context' containing text data.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping words to their indices. Special tokens: <PAD> for padding the contexts, <UNK> for unseen words in test set.\n",
    "    \"\"\"\n",
    "    word_to_idx = defaultdict(lambda: len(word_to_idx))  # Use defaultdict for automatic indexing\n",
    "\n",
    "    # Add special tokens\n",
    "    word_to_idx[\"<PAD>\"]  # Ensure padding token is in the dictionary\n",
    "\n",
    "    for text in data['context']:\n",
    "        for token in text.lower().split():  # Lowercase and split on whitespace\n",
    "            word_to_idx[token]\n",
    "\n",
    "    # Convert defaultdict to regular dict\n",
    "    word_to_idx = dict(word_to_idx)\n",
    "    \n",
    "    return word_to_idx\n",
    "    \n",
    "def data_load(batch_size=32, shuffle=True):\n",
    "    \"\"\"\n",
    "    Load and preprocess the dataset, and create data loaders for training and testing.\n",
    "\n",
    "    Args:\n",
    "        batch_size (int, optional): Batch size for training and testing. Defaults to 32.\n",
    "        shuffle (bool, optional): Whether to shuffle the training data. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the training data loader, testing data loader,\n",
    "               word-to-idx dictionary, and the output dimension.\n",
    "    \"\"\"\n",
    "    # Load dataset\n",
    "    print(\"load split dataset...\")\n",
    "    train_data = pd.read_csv('train_split.csv', sep=',', header=0)  # pay attention to parameters here\n",
    "    test_data = pd.read_csv('test_split.csv', sep=',', header=0)\n",
    "\n",
    "    train_data.columns = ['word_sense', 'word_form', 'index', 'context']\n",
    "    test_data.columns = ['word_sense', 'word_form', 'index', 'context']\n",
    "    print(\"length of train set:\",len(train_data))\n",
    "    print(\"length of test set:\",len(test_data))\n",
    "\n",
    "    # Build word_to_idx dictionary\n",
    "    print(\"build word_to_idx dictionary...\")\n",
    "    word_to_idx = build_word_to_idx(train_data)\n",
    "    word_to_idx['<UNK>'] = len(word_to_idx)\n",
    "    print(\"vocab_size:\", len(word_to_idx))\n",
    "\n",
    "    # Encode word senses\n",
    "    print(\"encode word senses...\")\n",
    "    combined_data = pd.concat([train_data, test_data]) \n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(combined_data['word_sense'])\n",
    "    output_dim = len(label_encoder.classes_)\n",
    "    print(\"number of distinguished word senses(output_dim):\", output_dim)\n",
    "\n",
    "    # Preprocess data\n",
    "    print(\"preprocess data...\")\n",
    "    train_dataset = CustomDataset(train_data, word_to_idx, label_encoder)\n",
    "    test_dataset = CustomDataset(test_data, word_to_idx, label_encoder)\n",
    "\n",
    "    # Load batches\n",
    "    print(\"load batches...\")\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_batch)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "    print(\"loaded!\")\n",
    "\n",
    "    return train_loader, test_loader, word_to_idx, output_dim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv('train_split.csv', sep=',', header=0)\n",
    "# train_data.columns = ['word_sense', 'word_form', 'index', 'context']\n",
    "# # summarize by word_sense\n",
    "# word_sense_summary = train_data['word_sense'].value_counts()\n",
    "# print(word_sense_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 LSTM for Word Sense Disambiguation\n",
    "\n",
    "In this section, we will train an LSTM model to predict word senses based on *contextualized representations*.\n",
    "\n",
    "You can read more about LSTMs [here](https://colah.github.io/posts/2015-08-Understanding-LSTMs/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "We will use a **bidirectional** Long Short-Term Memory (LSTM) network to create a representation for the sentences and a **linear** classifier to predict the sense of each word.\n",
    "\n",
    "As we discussed in the lecture, bidirectional LSTM is using **two** hidden states: one that goes in the left-to-right direction, and another one that goes in the right-to-left direction. PyTorch documentation on LSTMs can be found [here](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html). It says that if the bidirectional parameter is set to True, then \"h_n will contain a concatenation of the final forward and reverse hidden states, respectively.\" Keep it in mind because you will have to ensure that your linear layer for prediction takes input of that size.\n",
    "\n",
    "When we initialize the model, we need a few things:\n",
    "\n",
    "1) An embedding layer: a dictionary from which we can obtain word embeddings\n",
    "2) A LSTM-module to obtain contextual representations\n",
    "3) A classifier that computes scores for each word-sense given *some* input\n",
    "\n",
    "The general procedure is the following:\n",
    "\n",
    "1) For each word in the sentence, obtain word embeddings\n",
    "2) Run the embedded sentences through the LSTM\n",
    "3) Select the appropriate hidden state\n",
    "4) Predict the word-sense \n",
    "\n",
    "**Suggestion for efficiency:** *Use a low dimensionality (32) for word embeddings and the LSTM when developing and testing the code, then scale up when running the full training/tests*\n",
    "\n",
    "Your tasks will be to create **two different models** (both follow the two outlines described above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your first model should make a prediction from the LSTM's representation of the target word.\n",
    "\n",
    "In particular, you run your LSTM on the context in which the target word is used. LSTM will produce a sequence of hidden states. Each hidden state corresponds to a single word from the input context. For example, you should be able to get 37 hidden states for a context that has 37 words/elements in it. Next, take the LSTM's representation of the target word. For example, it can be hidden state number 5, because the fifth word in your context is the target word that you want to predict the meaning for. This target's word representation is the input to your linear layer that makes the final prediction.\n",
    "\n",
    "**[5 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WSDModel_approach1(nn.Module):\n",
    "    \"\"\"\n",
    "    Word Sense Disambiguation Model using LSTM with a bidirectional architecture.\n",
    "    You should make a prediction from the LSTM's representation of the target word.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): Size of the vocabulary.\n",
    "        embedding_dim (int): Dimensionality of word embeddings.\n",
    "        hidden_dim (int): Dimensionality of the hidden state of the LSTM.\n",
    "        output_dim (int): Dimensionality of the output.\n",
    "\n",
    "    Attributes:\n",
    "        embeddings (nn.Embedding): Embedding layer.\n",
    "        rnn (nn.LSTM): LSTM module.\n",
    "        classifier (nn.Linear): Linear classifier.\n",
    "\n",
    "    Methods:\n",
    "        forward(context, target_index): Forward pass through the model.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(WSDModel_approach1, self).__init__()\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # LSTM module\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True) # `bidirectional=True` => output.shape: (num_layers * num_directions, batch_size, hidden_size)\n",
    "        \n",
    "        # Linear classifier\n",
    "        self.classifier = nn.Linear(hidden_dim * 2, output_dim)   # why `*2`: concatenating forward and backward hidden states\n",
    "    \n",
    "    def forward(self, context, target_index):\n",
    "        \"\"\"\n",
    "        Forward pass of the WSDModel_approach1.\n",
    "    \n",
    "        Args:\n",
    "            context (torch.Tensor): Tensor of shape (batch_size, seq_length) containing the input word indices.\n",
    "            target_index (torch.Tensor): Tensor of shape (batch_size,) containing the indices of the target words within the context.\n",
    "    \n",
    "        Returns:\n",
    "            torch.Tensor: Tensor of shape (batch_size, output_dim) containing the model's predictions for each target word.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Obtain word embeddings\n",
    "        embedded_context = self.embeddings(context)\n",
    "        \n",
    "        # Run the embedded context through the LSTM\n",
    "        output, (_, _) = self.rnn(embedded_context) # output, (hidden,cell)\n",
    "        \n",
    "        # Select the appropriate hidden state (representation of the target word)\n",
    "        target_hidden = output[torch.arange(output.size(0)), target_index, :]  # get the target hidden state\n",
    "        \n",
    "        # Predict the word-sense\n",
    "        predictions = self.classifier(target_hidden)\n",
    "        \n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your second model should make a prediction from the final hidden state of your LSTM.\n",
    "\n",
    "In particular, do the same first steps as in the first approach. But then to make a prediction with your linear layer, you will need to take the last hidden state that your LSTM produces for the whole sequence.\n",
    "\n",
    "**[5 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WSDModel_approach2(nn.Module):\n",
    "    \"\"\"\n",
    "    Word Sense Disambiguation Model using LSTM with a bidirectional architecture.\n",
    "    You should make a prediction from the final hidden state of your LSTM.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): Size of the vocabulary.\n",
    "        embedding_dim (int): Dimensionality of word embeddings.\n",
    "        hidden_dim (int): Dimensionality of the hidden state of the LSTM.\n",
    "        output_dim (int): Dimensionality of the output.\n",
    "\n",
    "    Attributes:\n",
    "        embeddings (nn.Embedding): Embedding layer.\n",
    "        rnn (nn.LSTM): LSTM module.\n",
    "        classifier (nn.Linear): Linear classifier.\n",
    "\n",
    "    Methods:\n",
    "        forward(context): Forward pass through the model.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(WSDModel_approach2, self).__init__()\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # LSTM module\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # Linear classifier\n",
    "        self.classifier = nn.Linear(hidden_dim * 2, output_dim)  # why `*2`: concatenating forward and backward hidden states\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        \"\"\"\n",
    "        Forward pass of the WSDModel_approach2.\n",
    "    \n",
    "        Args:\n",
    "            batch (torch.Tensor): Tensor of shape (batch_size, seq_length) containing the input word indices.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Tensor of shape (batch_size, output_dim) containing the model's predictions for each final hidden state.\n",
    "        \"\"\"\n",
    "        # Extract relevant data from the batch\n",
    "        context = batch # here `batch` is `inputs`\n",
    "\n",
    "        # Obtain word embeddings\n",
    "        embedded_context = self.embeddings(context)\n",
    "        \n",
    "        # Run the embedded context through the LSTM\n",
    "        _, (hidden, _) = self.rnn(embedded_context) \n",
    "        final_hidden = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1) # take the last hidden state \n",
    "        # print(final_hidden.shape)\n",
    "\n",
    "        # Predict the word-sense\n",
    "        predictions = self.classifier(final_hidden)\n",
    "        \n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing the Model\n",
    "\n",
    "Now we are ready to train and test our model. What we need now is a loss function, an optimizer, and our data. \n",
    "\n",
    "- First, create the loss function and the optimizer.\n",
    "- Next, iterate over the number of epochs (i.e., how many times we let the model see our data). \n",
    "- For each epoch, iterate over the dataset to obtain batches. Use the batch as input to the model, and let the model output scores for the different word senses.\n",
    "- For each model output, calculate the loss (and print the loss) on the output and update the model parameters.\n",
    "- Reset the gradients and repeat.\n",
    "- After all epochs are done, test your trained model on the test set and calculate the total and per-word-form accuracy of your model.\n",
    "\n",
    "Implement the training and testing of the model.\n",
    "\n",
    "**[4 marks]**\n",
    "\n",
    "**Suggestion for efficiency:** *When developing your model, try training and testing the model on one or two batches (for each epoch) of data to make sure everything works! It's very annoying if you train for N epochs to find out that something went wrong when testing the model, or to find that something goes wrong when moving from epoch 0 to epoch 1.*\n",
    "\n",
    "Do not forget to save your best models as .pickle files. The results should be reproducible for us to evaluate your models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "epochs = 5\n",
    "batch_size = 8\n",
    "embedding_dim = 256 # 32 - use a low dimensionality when developing and testing the code\n",
    "hidden_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load split dataset...\n",
      "length of train set: 60839\n",
      "length of test set: 15210\n",
      "build word_to_idx dictionary...\n",
      "vocab_size: 70479\n",
      "encode word senses...\n",
      "number of distinguished word senses(output_dim): 222\n",
      "preprocess data...\n",
      "load batches...\n",
      "loaded!\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_loader, test_loader, word_to_idx, output_dim = data_load(batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_iter = iter(train_loader)\n",
    "# train_batch = next(train_iter)\n",
    "\n",
    "# print(\"train_loader sample:\",train_batch) # the first batch (8 sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_1(model, test_loader):\n",
    "    \"\"\"\n",
    "    Test the WSDModel_approach1 on the test data.\n",
    "\n",
    "    Args:\n",
    "        model (WSDModel_approach1): The trained WSD model.\n",
    "        test_loader (DataLoader): DataLoader for the test dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (float, dict) Accuracy of the model on the test dataset, \n",
    "               and per-word-form accuracy\n",
    "\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Dictionary to store correct and total predictions for each word form\n",
    "    word_form_stats = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs = batch['context']\n",
    "            target_indices = batch['target_index']\n",
    "            labels = batch['word_sense']\n",
    "            word_forms = batch['word_form']\n",
    "            word_sense_counts = batch['word_sense_counts']  # Number of senses for each word form\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            target_indices = target_indices.to(device)\n",
    "            labels = labels.to(device)\n",
    "            word_forms = word_forms.to(device)\n",
    "            word_sense_counts = word_sense_counts.to(device)\n",
    "      \n",
    "            outputs = model(inputs, target_indices)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update word form stats\n",
    "            for word_form, label, prediction, sense_count in zip(word_forms, labels, predicted, word_sense_counts):\n",
    "                word_form = word_form.item()  # convert tensor to scalar\n",
    "                sense_count = sense_count.item()\n",
    "                if word_form not in word_form_stats:\n",
    "                    word_form_stats[word_form] = {'correct': 0, 'total': 0, 'sense_count': sense_count}\n",
    "                word_form_stats[word_form]['total'] += 1\n",
    "                if label == prediction:\n",
    "                    word_form_stats[word_form]['correct'] += 1\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    # Calculate per-word-form accuracy with weighting\n",
    "    per_word_form_accuracy = {}\n",
    "    for word_form, stats in word_form_stats.items():\n",
    "        raw_accuracy = stats['correct'] / stats['total']\n",
    "        weighted_accuracy = raw_accuracy / stats['sense_count']\n",
    "        per_word_form_accuracy[word_form] = {\n",
    "        'accuracy': 100 * weighted_accuracy,\n",
    "        'sense_count': stats['sense_count']\n",
    "    }\n",
    "    \n",
    "    return accuracy, per_word_form_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build model...\n",
      "training model 1...\n",
      "epoch 1, average loss: 1.1483\n",
      "\taccuracy on test set: 70.30%\n",
      "epoch 2, average loss: 0.6502\n",
      "\taccuracy on test set: 71.89%\n",
      "epoch 3, average loss: 0.3751\n",
      "\taccuracy on test set: 72.81%\n",
      "epoch 4, average loss: 0.1753\n",
      "\taccuracy on test set: 73.53%\n",
      "\tBest model saved!\n",
      "epoch 5, average loss: 0.0881\n",
      "\taccuracy on test set: 73.16%\n",
      "training finished!\n"
     ]
    }
   ],
   "source": [
    "print(\"build model...\")\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "model_1 = WSDModel_approach1(len(word_to_idx), embedding_dim, hidden_dim, output_dim)\n",
    "model_1.to(device)\n",
    "optimizer_1 = optim.Adam(model_1.parameters(), lr=learning_rate)\n",
    "\n",
    "#best_accuracy_1 = 0.0 # set the threshold value when best_model has existed\n",
    "best_accuracy_1 = 73.41\n",
    "best_model_path_1 = 'best_model_1.pickle'\n",
    "\n",
    "print(\"training model 1...\")\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    # train model\n",
    "    model_1.train()  # train mode\n",
    "    for batch in train_loader:\n",
    "\n",
    "        # reset gradient\n",
    "        optimizer_1.zero_grad()\n",
    "        \n",
    "        # forward\n",
    "        inputs = batch['context']\n",
    "        target_indices = batch['target_index']\n",
    "        labels = batch['word_sense']\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        target_indices = target_indices.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model_1(inputs, target_indices)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer_1.step()\n",
    "        \n",
    "        # accumulate losses\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # calculate average loss\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"epoch {epoch + 1}, average loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # monitor the total accuracy during training\n",
    "    accuracy, _ = test_model_1(model_1, test_loader)\n",
    "    print(f\"\\taccuracy on test set: {accuracy:.2f}%\")\n",
    "    if accuracy > best_accuracy_1:\n",
    "        best_accuracy_1 = accuracy\n",
    "        torch.save(model_1.state_dict(), best_model_path_1)\n",
    "        print(\"\\tBest model saved!\")\n",
    "\n",
    "print(\"training finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final test accuracy for model 1: 73.53%\n",
      "per_word_form_accuracy(sorted by weighted accuracy): 'bad': 19.98%, 4; 'professional': 16.53%, 5; 'major': 16.15%, 4; 'common': 16.08%, 4; 'active': 15.68%, 5; 'order': 15.66%, 5; 'critical': 15.14%, 5; 'time': 14.49%, 5; 'positive': 14.32%, 5; 'national': 12.72%, 6; 'security': 12.31%, 7; 'physical': 11.71%, 6; 'position': 11.01%, 6; 'place': 11.01%, 7; 'force': 10.28%, 8; 'point': 9.70%, 8; 'extend': 8.99%, 7; 'line': 8.80%, 11; 'regular': 8.62%, 8; 'life': 8.23%, 9; 'bring': 7.85%, 8; 'case': 7.79%, 8; 'see': 7.42%, 11; 'serve': 7.40%, 9; 'keep': 7.23%, 11; 'find': 6.72%, 10; 'lead': 6.71%, 8; 'hold': 6.29%, 11; 'follow': 5.93%, 11; 'build': 4.88%, 10\n"
     ]
    }
   ],
   "source": [
    "# Load the best model and evaluate it on the test set\n",
    "best_model_1 = WSDModel_approach1(len(word_to_idx), embedding_dim, hidden_dim, output_dim)\n",
    "best_model_1.load_state_dict(torch.load(best_model_path_1))\n",
    "best_model_1.to(device)\n",
    "best_model_1.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# generate idx_to_word dictionary\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    final_accuracy, per_word_idx_accuracy = test_model_1(best_model_1, test_loader)\n",
    "    print(f\"final test accuracy for model 1: {final_accuracy:.2f}%\")\n",
    "\n",
    "    per_word_form_accuracy_1 = {}\n",
    "    for idx, stats in per_word_idx_accuracy.items():\n",
    "        accuracy,sense_count = stats.values()\n",
    "        word = idx_to_word[idx] # here per word maps one word-form\n",
    "        per_word_form_accuracy_1[word] = {\n",
    "        'accuracy': accuracy,\n",
    "        'sense_count': sense_count\n",
    "    }\n",
    "\n",
    "    # sort by weighted accuracy \n",
    "    sorted_per_word_form_accuracy_1 = dict(sorted(per_word_form_accuracy_1.items(), key=lambda item: item[1]['accuracy'], reverse=True))\n",
    "\n",
    "# print\n",
    "output_1 = '; '.join([f\"'{word}': {stats['accuracy']:.2f}%, {stats['sense_count']}\" for word, stats in sorted_per_word_form_accuracy_1.items()])\n",
    "print(f\"per_word_form_accuracy(sorted by weighted accuracy): {output_1}\") \n",
    "    \n",
    "## record of final accuracy on test set\n",
    "# Note here: The same combination of hyperparameters does not always achieve the same accuracy! => To save the best model each time is needed...\n",
    "# learning_rate = 0.001, epochs = 3, batch_size = 8, embedding_dim = 32, hidden_dim = 64 => 68.65%\n",
    "# learning_rate = 0.001, epochs = 5, batch_size = 8, embedding_dim = 128, hidden_dim = 64 => 70.93%\n",
    "# learning_rate = 0.0005, epochs = 4, batch_size = 8, embedding_dim = 256, hidden_dim = 256 => 73.53%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_2(model, test_loader):\n",
    "    \"\"\"\n",
    "    Test the WSDModel_approach2 on the test data.\n",
    "\n",
    "    Args:\n",
    "        model (WSDModel_approach2): The trained WSD model.\n",
    "        test_loader (DataLoader): DataLoader for the test dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (float, dict) Accuracy of the model on the test dataset, \n",
    "               and per-word-form accuracy\n",
    "\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Dictionary to store correct and total predictions for each word form\n",
    "    word_form_stats = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs = batch['context']\n",
    "            labels = batch['word_sense']\n",
    "            word_forms = batch['word_form']\n",
    "            word_sense_counts = batch['word_sense_counts']  # Number of senses for each word form\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            word_forms = word_forms.to(device)\n",
    "            word_sense_counts = word_sense_counts.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "             # Update word form stats\n",
    "            for word_form, label, prediction, sense_count in zip(word_forms, labels, predicted, word_sense_counts):\n",
    "                word_form = word_form.item()  # convert tensor to scalar\n",
    "                sense_count = sense_count.item()\n",
    "                if word_form not in word_form_stats:\n",
    "                    word_form_stats[word_form] = {'correct': 0, 'total': 0, 'sense_count': sense_count}\n",
    "                word_form_stats[word_form]['total'] += 1\n",
    "                if label == prediction:\n",
    "                    word_form_stats[word_form]['correct'] += 1\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    # Calculate per-word-form accuracy with weighting\n",
    "    per_word_form_accuracy = {}\n",
    "    for word_form, stats in word_form_stats.items():\n",
    "        raw_accuracy = stats['correct'] / stats['total']\n",
    "        weighted_accuracy = raw_accuracy / stats['sense_count']\n",
    "        per_word_form_accuracy[word_form] = {\n",
    "        'accuracy': 100 * weighted_accuracy,\n",
    "        'sense_count': stats['sense_count']\n",
    "    }\n",
    "        \n",
    "    return accuracy, per_word_form_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model 2...\n",
      "epoch 1, average loss: 4.7453\n",
      "\taccuracy on test set: 15.47%\n",
      "epoch 2, average loss: 3.8658\n",
      "\taccuracy on test set: 29.11%\n",
      "epoch 3, average loss: 2.3848\n",
      "\taccuracy on test set: 47.34%\n",
      "epoch 4, average loss: 1.3691\n",
      "\taccuracy on test set: 53.99%\n",
      "epoch 5, average loss: 0.9272\n",
      "\taccuracy on test set: 57.58%\n",
      "training finished!\n"
     ]
    }
   ],
   "source": [
    "# try model_2\n",
    "model_2 = WSDModel_approach2(len(word_to_idx), embedding_dim, hidden_dim, output_dim)\n",
    "model_2.to(device)\n",
    "optimizer_2 = optim.Adam(model_2.parameters(), lr=learning_rate)\n",
    "\n",
    "best_accuracy_2 = 58.42 # set the threshold value when best_model has existed\n",
    "best_model_path_2 = 'best_model_2.pickle'\n",
    "\n",
    "print(\"training model 2...\")\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    # train model\n",
    "    model_2.train()  # train mode\n",
    "    for batch in train_loader:\n",
    "        # reset gradient\n",
    "        optimizer_2.zero_grad()\n",
    "        \n",
    "        # forward\n",
    "        inputs = batch['context']\n",
    "        labels = batch['word_sense']\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model_2(inputs)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer_2.step()\n",
    "        \n",
    "        # accumulate losses\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # calculate average loss\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"epoch {epoch + 1}, average loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # monitor the total accuracy during training\n",
    "    accuracy, _ = test_model_2(model_2, test_loader)\n",
    "    print(f\"\\taccuracy on test set: {accuracy:.2f}%\")\n",
    "    if accuracy > best_accuracy_2:\n",
    "        best_accuracy_2 = accuracy\n",
    "        torch.save(model_2.state_dict(), best_model_path_2)\n",
    "        print(\"\\tBest model saved!\")\n",
    "\n",
    "print(\"training finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final test accuracy for model 2: 58.42%\n",
      "per_word_form_accuracy(sorted by weighted accuracy): 'bad': 17.52%, 4; 'professional': 13.27%, 5; 'order': 12.70%, 5; 'positive': 11.91%, 5; 'active': 11.58%, 5; 'common': 11.54%, 4; 'critical': 9.66%, 5; 'major': 9.34%, 4; 'physical': 9.07%, 6; 'position': 8.95%, 6; 'time': 8.65%, 5; 'security': 8.62%, 7; 'line': 8.44%, 11; 'point': 8.42%, 8; 'force': 8.37%, 8; 'place': 8.32%, 7; 'national': 7.82%, 6; 'extend': 7.37%, 7; 'see': 6.91%, 11; 'life': 6.66%, 9; 'keep': 6.60%, 11; 'regular': 6.23%, 8; 'serve': 5.97%, 9; 'lead': 5.17%, 8; 'bring': 5.16%, 8; 'find': 4.96%, 10; 'case': 4.82%, 8; 'hold': 4.67%, 11; 'follow': 4.31%, 11; 'build': 2.90%, 10\n"
     ]
    }
   ],
   "source": [
    "# Load the best model and evaluate it on the test set\n",
    "best_model_2 = WSDModel_approach2(len(word_to_idx), embedding_dim, hidden_dim, output_dim)\n",
    "best_model_2.load_state_dict(torch.load(best_model_path_2))\n",
    "best_model_2.to(device)\n",
    "best_model_2.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad():\n",
    "    final_accuracy, per_word_idx_accuracy = test_model_2(best_model_2, test_loader)\n",
    "    print(f\"final test accuracy for model 2: {final_accuracy:.2f}%\")\n",
    "\n",
    "    per_word_form_accuracy_2 = {}\n",
    "    for idx, stats in per_word_idx_accuracy.items():\n",
    "        accuracy,sense_count = stats.values()\n",
    "        word = idx_to_word[idx] # here per word maps one word-form\n",
    "        per_word_form_accuracy_2[word] = {\n",
    "        'accuracy': accuracy,\n",
    "        'sense_count': sense_count\n",
    "    }\n",
    "\n",
    "    # sort by weighted accuracy \n",
    "    sorted_per_word_form_accuracy_2 = dict(sorted(per_word_form_accuracy_2.items(), key=lambda item: item[1]['accuracy'], reverse=True))\n",
    "\n",
    "# print\n",
    "output_2 = '; '.join([f\"'{word}': {stats['accuracy']:.2f}%, {stats['sense_count']}\" for word, stats in sorted_per_word_form_accuracy_2.items()])\n",
    "print(f\"per_word_form_accuracy(sorted by weighted accuracy): {output_2}\") \n",
    "\n",
    "## record of final accuracy on test set\n",
    "# adding epochs here can bring obvious improvement => why? learning more to counteract the negative impacts brought by the \"crude\" prediction target...\n",
    "# learning_rate = 0.001, epochs = 3, batch_size = 8, embedding_dim = 32, hidden_dim = 64 => 16.96%\n",
    "# learning_rate = 0.001, epochs = 8, batch_size = 8, embedding_dim = 128, hidden_dim = 64 => 53.10% (a great improvement!)\n",
    "# learning_rate = 0.0005, epochs = 7, batch_size = 8, embedding_dim = 256, hidden_dim = 256 => 58.42%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## try to figure out the optimal combination of hyperparameters for approach 1 (considering time cost, only run batch_size=8 completely)\n",
    "# define model training and evaluation functions\n",
    "# def train_model(model, train_loader, optimizer, loss_function, device):\n",
    "#     model.train()\n",
    "#     total_loss = 0.0\n",
    "\n",
    "#     for batch in train_loader:\n",
    "#         inputs = batch['context']\n",
    "#         target_indices = batch['target_index']\n",
    "#         labels = batch['word_sense']\n",
    "\n",
    "#         inputs = inputs.to(device)\n",
    "#         target_indices = target_indices.to(device)\n",
    "#         labels = labels.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs, target_indices)\n",
    "#         loss = loss_function(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#     avg_loss = total_loss / len(train_loader)\n",
    "#     return avg_loss\n",
    "\n",
    "# # evaluation: test_model_1()\n",
    "\n",
    "# # define grid search function\n",
    "# def grid_search(params, train_loader, test_loader, device):\n",
    "\n",
    "#     for embedding_dim in params['embedding_dim']:\n",
    "#         for hidden_dim in params['hidden_dim']:\n",
    "#             for learning_rate in params['learning_rate']:\n",
    "#                 print(f'Training with embedding_dim={embedding_dim}, hidden_dim={hidden_dim}, learning_rate={learning_rate}...')\n",
    "\n",
    "#                 model = WSDModel_approach1(vocab_size=len(word_to_idx), embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_dim=output_dim).to(device)\n",
    "#                 optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#                 loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "#                 for epoch in range(params['epochs']):\n",
    "#                     train_loss = train_model(model, train_loader, optimizer, loss_function, device)\n",
    "#                     print(f'epoch {epoch + 1}, loss: {train_loss}')\n",
    "\n",
    "#                 accuracy = test_model_1(model, test_loader)\n",
    "#                 print(f'\\tAccuracy: {accuracy:.2f}%')\n",
    "\n",
    "#                 if round(accuracy, 2) > round(best_accuracy, 2):\n",
    "#                     print(f'\\tNew best accuracy: {accuracy:.2f}% (previous: {best_accuracy:.2f}%). Saving model...')\n",
    "#                     torch.save(model.state_dict(), best_model_path_1)\n",
    "#                     print(\"\\tBest model saved!\")\n",
    "#                     best_accuracy = accuracy\n",
    "#                     best_params = {\n",
    "#                         'embedding_dim': embedding_dim,\n",
    "#                         'hidden_dim': hidden_dim,\n",
    "#                         'learning_rate': learning_rate,\n",
    "#                         'accuracy': best_accuracy\n",
    "#                     }\n",
    "\n",
    "#     return best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define parameter grid\n",
    "# params = {\n",
    "#     'batch_size': [8,16,32,64],\n",
    "#     'embedding_dim': [64, 128, 256],\n",
    "#     'hidden_dim': [64, 128, 256],\n",
    "#     'learning_rate': [0.001, 0.0005, 0.0001],\n",
    "#     'epochs': 5\n",
    "# }\n",
    "\n",
    "# best_params = None\n",
    "# #best_accuracy = 0.0\n",
    "# best_accuracy = 70.93 # Initialization(pay attention to the scale!)\n",
    "\n",
    "# # load data for each batch_size\n",
    "# for batch_size in params['batch_size']:\n",
    "#     print(f'Loading data with batch_size = {batch_size}...')\n",
    "#     train_loader, test_loader, word_to_idx, output_dim = data_load(batch_size = batch_size, shuffle=True)\n",
    "\n",
    "#     # run grid search\n",
    "#     current_best_params = grid_search(params, train_loader, test_loader, device)\n",
    "#     print(f'\\tBest Parameters for batch_size={batch_size}: {current_best_params}')\n",
    "\n",
    "#     # Update global best parameters if current batch size yields better accuracy\n",
    "#     if current_best_params and current_best_params['accuracy'] > best_accuracy:\n",
    "#         best_accuracy = current_best_params['accuracy']\n",
    "#         best_params = current_best_params\n",
    "\n",
    "# # After all batch sizes are processed, print the overall best parameters\n",
    "# print(f'Overall Best Parameters: {best_params}')\n",
    "\n",
    "# ## record of grid search\n",
    "# # Best Parameters for batch_size=8: {'embedding_dim': 256, 'hidden_dim': 256, 'learning_rate': 0.0005, 'accuracy': 73.64891518737673}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Fine-tuning and Testing BERT for Word Sense Disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section of the lab, you'll try out the transformer, specifically the BERT model. For this, we'll use the Hugging Face library ([https://huggingface.co/](https://huggingface.co/)).\n",
    "\n",
    "You can find the documentation for the BERT model [here](https://huggingface.co/transformers/model_doc/bert.html) and a general usage guide [here](https://huggingface.co/transformers/v2.9.1/quickstart.html).\n",
    "\n",
    "What we're going to do is *fine-tune* the BERT model, i.e., update the weights of a pre-trained model. That is, we have a model that is pre-trained on masked language modeling and next sentence prediction (kind of basic, general tasks which are useful for a lot of more specific tasks), but now we apply it to word sense disambiguation with the word representations it has learned.\n",
    "\n",
    "We'll use the same data splits for training and testing as before, but this time you will use a different dataloader.\n",
    "\n",
    "Now you create an iterator that collects N sentences (where N is the batch size) then use the BertTokenizer to transform the sentence into integers. For your dataloader, remember to:\n",
    "* Shuffle the data in each batch\n",
    "* Make sure you get a new iterator for each *epoch*\n",
    "* Create a vocabulary of *sense-labels* so you can calculate accuracy \n",
    "\n",
    "We then pass this batch into the BERT model (you must have pre-loaded its weights) and update the weights (fine-tune). The BERT model will encode the sentence, then we send this encoded sentence into a prediction layer and collect what it outputs.\n",
    "\n",
    "As input to the prediction layer, you are free to play with different types of information. For example, the expected way would be to use CLS representation. You can also use other representations and compare them.\n",
    "\n",
    "About the hyperparameters and training:\n",
    "* For BERT, usually a lower learning rate works best, between 0.0001-0.000001.\n",
    "* BERT takes a lot of resources, running it on CPU will take ages, utilize the GPUs :)\n",
    "* Since BERT takes a lot of resources, use a small batch size (4-8)\n",
    "* Computing the BERT representation, make sure you pass the mask\n",
    "\n",
    "**[12 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 0. define hyperparameters\n",
    "learning_rate = 1e-5 # For BERT, usually a lower learning rate works best, between 0.0001-0.000001.\n",
    "epochs = 3\n",
    "batch_size = 8 # Since BERT takes a lot of resources, use a small batch size (4-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. create a new dataloader (use the BertTokenizer to transform the sentence into integers)\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "## 1.1 create data preprocessing class\n",
    "class CustomBertDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom PyTorch dataset for word sense disambiguation using BERT.\n",
    "\n",
    "    Attributes:\n",
    "        data (DataFrame): The DataFrame containing the dataset.\n",
    "        tokenizer (PreTrainedTokenizer): The BERT tokenizer.\n",
    "        max_length (int): The maximum length for tokenized sequences.\n",
    "    \n",
    "    Args:\n",
    "        data (DataFrame): The DataFrame containing the dataset.\n",
    "        tokenizer (PreTrainedTokenizer): The BERT tokenizer.\n",
    "        label_encoder (LabelEncoder): An instance of sklearn's LabelEncoder for encoding word senses.\n",
    "        max_length (int): The maximum length for tokenized sequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, tokenizer, label_encoder, max_length=128):\n",
    "        \"\"\"\n",
    "        Initializes the dataset with data, tokenizer, and maximum sequence length.\n",
    "\n",
    "        Args:\n",
    "            data (DataFrame): The DataFrame containing the dataset.\n",
    "            tokenizer (PreTrainedTokenizer): The BERT tokenizer.\n",
    "            label_encoder (LabelEncoder): An instance of sklearn's LabelEncoder for encoding word senses.\n",
    "            max_length (int): The maximum length for tokenized sequences (default is 128).\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label_encoder = label_encoder\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of samples in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            int: The number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves a sample from the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the sample data with keys 'input_ids', \n",
    "                  'attention_mask', and 'word_sense'.\n",
    "                  - 'input_ids' (torch.Tensor): The token IDs of the input context.\n",
    "                  - 'attention_mask' (torch.Tensor): The attention mask for the input context.\n",
    "                  - 'word_sense' (int): The encoded word sense label.\n",
    "        \"\"\"\n",
    "        row = self.data.iloc[idx]\n",
    "        word_sense = row['word_sense']\n",
    "        word_form = row['word_form']\n",
    "        index = row['index']\n",
    "        context = row['context']\n",
    "\n",
    "        # Encode word sense\n",
    "        encoded_word_sense = self.label_encoder.transform([word_sense])[0]\n",
    "        \n",
    "        # Tokenize the context\n",
    "        encoded_dict = self.tokenizer(\n",
    "            text=context,\n",
    "            add_special_tokens=True, # Add special tags [CLS] and [SEP]\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt' # Return PyTorch tensors\n",
    "        )\n",
    "\n",
    "        # Flatten to 1D tensors\n",
    "        input_ids = encoded_dict['input_ids'].flatten()\n",
    "        attention_mask = encoded_dict['attention_mask'].flatten()\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'word_sense': int(encoded_word_sense)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.2 def dataloader function\n",
    "def dataloader_for_bert(batch_size, shuffle=True):\n",
    "    \"\"\"\n",
    "    Creates a DataLoader for a dataset suitable for BERT-based word sense disambiguation.\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): The number of samples per batch to load.\n",
    "        shuffle (bool): Whether to shuffle the data at every epoch. Default is True.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the training data loader, testing data loader, and the output dimension.\n",
    "    \"\"\"\n",
    "    # Load dataset\n",
    "    print(\"load split dataset...\")\n",
    "    train_data = pd.read_csv('train_split.csv', sep=',', header=0) \n",
    "    test_data = pd.read_csv('test_split.csv', sep=',', header=0)\n",
    "\n",
    "    train_data.columns = ['word_sense', 'word_form', 'index', 'context']\n",
    "    test_data.columns = ['word_sense', 'word_form', 'index', 'context']\n",
    "    \n",
    "    # Initialize the BERT tokenizer\n",
    "    print(\"initialize the BERT tokenizer...\")\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Encode word senses\n",
    "    print(\"encode word senses...\")\n",
    "    combined_data = pd.concat([train_data, test_data]) \n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(combined_data['word_sense'])\n",
    "    output_dim = len(label_encoder.classes_)\n",
    "    print(\"number of distinguished word senses(output_dim):\", output_dim)\n",
    "    \n",
    "    # Preprocess data\n",
    "    print(\"preprocess data...\")\n",
    "    train_dataset = CustomBertDataset(train_data, tokenizer, label_encoder)\n",
    "    test_dataset = CustomBertDataset(test_data, tokenizer, label_encoder)\n",
    "\n",
    "    # Load batches\n",
    "    print(\"load batches...\")\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    print(\"loaded!\")\n",
    "\n",
    "    return train_loader, test_loader, output_dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load split dataset...\n",
      "initialize the BERT tokenizer...\n",
      "encode word senses...\n",
      "number of distinguished word senses(output_dim): 222\n",
      "preprocess data...\n",
      "load batches...\n",
      "loaded!\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_loader, test_loader, output_dim = dataloader_for_bert(batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. build model\n",
    "## 2.1 create BERT_WSD class\n",
    "class BERT_WSD(nn.Module):\n",
    "    \"\"\"\n",
    "    A custom PyTorch model for word sense disambiguation using BERT.\n",
    "\n",
    "    This model uses a pretrained BERT model to generate representations for the input text,\n",
    "    and a linear classifier to predict the word sense.\n",
    "\n",
    "    Attributes:\n",
    "        bert (BertModel): The pretrained BERT model.\n",
    "        classifier (nn.Linear): The linear layer for classification.\n",
    "\n",
    "    Args:\n",
    "        output_dim (int): The number of output classes for the classifier.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_dim):\n",
    "        \"\"\"\n",
    "        Initializes the BERT_WSD model with a pretrained BERT model and a classifier.\n",
    "\n",
    "        Args:\n",
    "            output_dim (int): The number of output classes for the classifier.\n",
    "        \"\"\"\n",
    "        super(BERT_WSD, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, output_dim)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Forward pass of the BERT_WSD model.\n",
    "\n",
    "        Args:\n",
    "            input_ids (torch.Tensor): Tensor of input IDs for BERT (tokenized text).\n",
    "            attention_mask (torch.Tensor): Tensor of attention masks for BERT.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output predictions from the classifier.\n",
    "        \"\"\"\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]  # [CLS] token representation => target indice?\n",
    "        predictions = self.classifier(cls_output)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine-tuning BERT model...\n",
      "epoch 1, average loss: 2.1864\n",
      "epoch 2, average loss: 0.9891\n",
      "epoch 3, average loss: 0.7455\n",
      "training finished!\n"
     ]
    }
   ],
   "source": [
    "## 2.2 initialize model, loss function, and optimizer\n",
    "model = BERT_WSD(output_dim=output_dim)\n",
    "model.to(device)\n",
    "# ensure that all the parameters require gradients\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 2.3 training\n",
    "print(\"fine-tuning BERT model...\")\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    # train model\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['word_sense'].to(device)\n",
    "\n",
    "        # reset gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # accumulate losses\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # calculate average loss\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"epoch {epoch + 1}, average loss: {avg_loss:.4f}\")\n",
    "\n",
    "print('training finished!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 75.19%\n",
      "Best model saved!\n"
     ]
    }
   ],
   "source": [
    "### 3. test model after all epochs are completed\n",
    "model.eval()\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "best_bert_accuracy = 74.76 # set the threshold value when best_model has existed\n",
    "best_bert_model_path = 'best_bert_model.pickle'\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['word_sense'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "accuracy = 100 * correct_predictions / total_predictions\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "if accuracy > best_bert_accuracy:\n",
    "    best_bert_accuracy = accuracy\n",
    "    torch.save(model.state_dict(), best_bert_model_path)\n",
    "    print(\"Best model saved!\")\n",
    "\n",
    "## record of final accuracy on test set\n",
    "# learning_rate = 1e-5, epochs = 3, batch_size = 4 => 74.76%\n",
    "# learning_rate = 1e-5, epochs = 3, batch_size = 8 => 75.19%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Explain the difference between the two LSTMs that you have implemented for word sense disambiguation.\n",
    "\n",
    "Important note: your LSTMs should be nearly the same, but your linear layer must take different inputs. Describe why and how you think this difference will affect the performance of different LSTMs. How does the contextual representation of the whole sequence perform? How does the representation of the target word perform? What is better and for what situations? Why do we observe these differences?\n",
    "\n",
    "What kind of representations are the different approaches using to predict word senses?\n",
    "\n",
    "**[4 marks]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bi-LSTM models process the input sequence in both forward and backward directions, allowing them to capture contextual information from both past and future tokens. For Bi-LSTMs, the final hidden state often serves as the representation of the whole sequence. \n",
    "\n",
    "Representations the different approaches using to predict word senses:\r",
    "- Approach 1: Uses the hidden state of the target word (local context).\n",
    "- Approach 2: Uses the final hidden state of the sequence (global context).\n",
    "\n",
    "Comparing different approaches:\n",
    "- Local Context Approach (Approach 1): Better when the word sense is highly dependent on nearby words (e.g., syntactic dependencies, local collocations).\n",
    "- Global Context Approach (Approach 2):  More suitable when broader sentence or document-level informatin influence the word sense.\n",
    "\n",
    "From the results above, the accuracy of Approach 1 is around *73%*, while the result of Approach 2 is around *58%*. For our context here is not so long, it is rational to get a **worse** result using Approach 2. Compared with the baseline result (around *30%*), Approach 2 model could perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Evaluate your model with per-word form *accuracy* and comment on the results you get. How does the model perform in comparison to the baseline, and how do the models compare to each other? \n",
    "\n",
    "Expand on the evaluation by sorting the word-forms by the number of senses they have. Are word forms with fewer senses easier to predict? Give a short explanation of the results you get based on the number of senses per word.\n",
    "\n",
    "**[4 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of MSC Baseline:\n",
      "per_word_form_accuracy(sorted by weighted accuracy): 'professional.a': 0.20%, 5; 'critical.a': 0.20%, 5; 'positive.a': 0.20%, 5; 'point.n': 0.12%, 8; 'life.n': 0.11%, 9; 'line.n': 0.09%, 11; 'see.v': 0.09%, 11; 'lead.v': 0.00%, 8; 'common.a': 0.00%, 4; 'find.v': 0.00%, 10; 'case.n': 0.00%, 8; 'security.n': 0.00%, 7; 'keep.v': 0.00%, 11; 'time.n': 0.00%, 5; 'build.v': 0.00%, 10; 'place.n': 0.00%, 7; 'physical.a': 0.00%, 6; 'major.a': 0.00%, 4; 'bad.a': 0.00%, 4; 'hold.v': 0.00%, 11; 'regular.a': 0.00%, 8; 'bring.v': 0.00%, 8; 'force.n': 0.00%, 8; 'serve.v': 0.00%, 9; 'follow.v': 0.00%, 11; 'extend.v': 0.00%, 7; 'national.a': 0.00%, 6; 'position.n': 0.00%, 6; 'order.n': 0.00%, 5; 'active.a': 0.00%, 5\n",
      "per_word_form_accuracy(sorted by the number of senses): 'line.n': 0.09%, 11; 'keep.v': 0.00%, 11; 'hold.v': 0.00%, 11; 'see.v': 0.09%, 11; 'follow.v': 0.00%, 11; 'find.v': 0.00%, 10; 'build.v': 0.00%, 10; 'life.n': 0.11%, 9; 'serve.v': 0.00%, 9; 'lead.v': 0.00%, 8; 'point.n': 0.12%, 8; 'case.n': 0.00%, 8; 'regular.a': 0.00%, 8; 'bring.v': 0.00%, 8; 'force.n': 0.00%, 8; 'security.n': 0.00%, 7; 'place.n': 0.00%, 7; 'extend.v': 0.00%, 7; 'physical.a': 0.00%, 6; 'national.a': 0.00%, 6; 'position.n': 0.00%, 6; 'time.n': 0.00%, 5; 'professional.a': 0.20%, 5; 'critical.a': 0.20%, 5; 'order.n': 0.00%, 5; 'active.a': 0.00%, 5; 'positive.a': 0.20%, 5; 'common.a': 0.00%, 4; 'major.a': 0.00%, 4; 'bad.a': 0.00%, 4\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "sorted_baseline_per_word_form_accuracy_1 = dict(sorted(baseline_per_word_form_accuracy.items(), key=lambda item: item[1]['accuracy'], reverse=True))\n",
    "sorted_baseline_per_word_form_accuracy_2 = dict(sorted(baseline_per_word_form_accuracy.items(), key=lambda item: item[1]['sense_count'], reverse=True))\n",
    "output_baseline1 = '; '.join([f\"'{word}': {stats['accuracy']:.2f}%, {stats['sense_count']}\" for word, stats in sorted_baseline_per_word_form_accuracy_1.items()])\n",
    "output_baseline2 = '; '.join([f\"'{word}': {stats['accuracy']:.2f}%, {stats['sense_count']}\" for word, stats in sorted_baseline_per_word_form_accuracy_2.items()])\n",
    "\n",
    "print(\"Evaluation of MSC Baseline:\")\n",
    "print(f\"per_word_form_accuracy(sorted by weighted accuracy): {output_baseline1}\") \n",
    "print(f\"per_word_form_accuracy(sorted by the number of senses): {output_baseline2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of Approach 1:\n",
      "per_word_form_accuracy(sorted by weighted accuracy): 'bad': 19.98%, 4; 'professional': 16.53%, 5; 'major': 16.15%, 4; 'common': 16.08%, 4; 'active': 15.68%, 5; 'order': 15.66%, 5; 'critical': 15.14%, 5; 'time': 14.49%, 5; 'positive': 14.32%, 5; 'national': 12.72%, 6; 'security': 12.31%, 7; 'physical': 11.71%, 6; 'position': 11.01%, 6; 'place': 11.01%, 7; 'force': 10.28%, 8; 'point': 9.70%, 8; 'extend': 8.99%, 7; 'line': 8.80%, 11; 'regular': 8.62%, 8; 'life': 8.23%, 9; 'bring': 7.85%, 8; 'case': 7.79%, 8; 'see': 7.42%, 11; 'serve': 7.40%, 9; 'keep': 7.23%, 11; 'find': 6.72%, 10; 'lead': 6.71%, 8; 'hold': 6.29%, 11; 'follow': 5.93%, 11; 'build': 4.88%, 10\n",
      "per_word_form_accuracy(sorted by the number of senses): 'line': 8.80%, 11; 'keep': 7.23%, 11; 'hold': 6.29%, 11; 'see': 7.42%, 11; 'follow': 5.93%, 11; 'find': 6.72%, 10; 'build': 4.88%, 10; 'life': 8.23%, 9; 'serve': 7.40%, 9; 'lead': 6.71%, 8; 'point': 9.70%, 8; 'case': 7.79%, 8; 'regular': 8.62%, 8; 'bring': 7.85%, 8; 'force': 10.28%, 8; 'security': 12.31%, 7; 'place': 11.01%, 7; 'extend': 8.99%, 7; 'physical': 11.71%, 6; 'national': 12.72%, 6; 'position': 11.01%, 6; 'time': 14.49%, 5; 'professional': 16.53%, 5; 'critical': 15.14%, 5; 'order': 15.66%, 5; 'active': 15.68%, 5; 'positive': 14.32%, 5; 'common': 16.08%, 4; 'major': 16.15%, 4; 'bad': 19.98%, 4\n",
      "\n",
      "Evaluation of Approach 2:\n",
      "per_word_form_accuracy(sorted by weighted accuracy): 'bad': 17.52%, 4; 'professional': 13.27%, 5; 'order': 12.70%, 5; 'positive': 11.91%, 5; 'active': 11.58%, 5; 'common': 11.54%, 4; 'critical': 9.66%, 5; 'major': 9.34%, 4; 'physical': 9.07%, 6; 'position': 8.95%, 6; 'time': 8.65%, 5; 'security': 8.62%, 7; 'line': 8.44%, 11; 'point': 8.42%, 8; 'force': 8.37%, 8; 'place': 8.32%, 7; 'national': 7.82%, 6; 'extend': 7.37%, 7; 'see': 6.91%, 11; 'life': 6.66%, 9; 'keep': 6.60%, 11; 'regular': 6.23%, 8; 'serve': 5.97%, 9; 'lead': 5.17%, 8; 'bring': 5.16%, 8; 'find': 4.96%, 10; 'case': 4.82%, 8; 'hold': 4.67%, 11; 'follow': 4.31%, 11; 'build': 2.90%, 10\n",
      "per_word_form_accuracy(sorted by the number of senses): 'line': 8.44%, 11; 'keep': 6.60%, 11; 'hold': 4.67%, 11; 'see': 6.91%, 11; 'follow': 4.31%, 11; 'find': 4.96%, 10; 'build': 2.90%, 10; 'life': 6.66%, 9; 'serve': 5.97%, 9; 'lead': 5.17%, 8; 'point': 8.42%, 8; 'case': 4.82%, 8; 'regular': 6.23%, 8; 'bring': 5.16%, 8; 'force': 8.37%, 8; 'security': 8.62%, 7; 'place': 8.32%, 7; 'extend': 7.37%, 7; 'physical': 9.07%, 6; 'national': 7.82%, 6; 'position': 8.95%, 6; 'time': 8.65%, 5; 'professional': 13.27%, 5; 'critical': 9.66%, 5; 'order': 12.70%, 5; 'active': 11.58%, 5; 'positive': 11.91%, 5; 'common': 11.54%, 4; 'major': 9.34%, 4; 'bad': 17.52%, 4\n"
     ]
    }
   ],
   "source": [
    "# regenerate the result dict (sort by the number of senses)\n",
    "sorted_per_word_form_accuracy_11 = dict(sorted(per_word_form_accuracy_1.items(), key=lambda item: item[1]['sense_count'], reverse=True))\n",
    "output_11 = '; '.join([f\"'{word}': {stats['accuracy']:.2f}%, {stats['sense_count']}\" for word, stats in sorted_per_word_form_accuracy_11.items()])\n",
    "\n",
    "sorted_per_word_form_accuracy_22 = dict(sorted(per_word_form_accuracy_2.items(), key=lambda item: item[1]['sense_count'], reverse=True))\n",
    "output_22 = '; '.join([f\"'{word}': {stats['accuracy']:.2f}%, {stats['sense_count']}\" for word, stats in sorted_per_word_form_accuracy_22.items()])\n",
    "\n",
    "print(\"Evaluation of Approach 1:\")\n",
    "print(f\"per_word_form_accuracy(sorted by weighted accuracy): {output_1}\") \n",
    "print(f\"per_word_form_accuracy(sorted by the number of senses): {output_11}\")\n",
    "print(\"\\nEvaluation of Approach 2:\")\n",
    "print(f\"per_word_form_accuracy(sorted by weighted accuracy): {output_2}\") \n",
    "print(f\"per_word_form_accuracy(sorted by the number of senses): {output_22}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compared to the baseline, LSTM approaches perform better: even the worst per-word form accuracy value is larger than the best one in MSC baseline model.\n",
    "- Both approaches show similar trends in per-word form accuracy, with some variations in specific words (e.g.,'major'), suggesting differences in how the models handle certain word forms or senses.\n",
    "- Considering the weighted accuracy, words with fewer senses tend to have higher accuracy scores compared to those with more senses, indicating that disambiguating between fewer options is generally easier.(the method of weighing?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: How do the LSTMs perform in comparison to BERT? What's the difference between representations obtained by the LSTMs and BERT?\n",
    "\n",
    "**[4 marks]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the training process and results, we can infer that BERT performs better than LSTMs while more time and computational resources are cost.\n",
    "\n",
    "- Differences in Representations:\n",
    "  - LSTMs: Generate contextual embeddings based on sequential processing. In bidirectional LSTMs, representations consider both directions, but still, the context captured is often less comprehensive than BERT’s due to sequential limitations.\n",
    "  - BERT: Based on transformer architecture, BERT generates deep contextual embeddings for each token, taking into account the entire sentence bidirectionally. Pre-trained on large corpora, BERT's embeddings have a robust understanding of language nuances, allowing superior performance in tasks like word sense disambiguation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: What could we do to improve all WSD models that we have worked with in this assignment?\n",
    "\n",
    "**[2 marks]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering a general method of improvement on all WSD models, we suggest **enhanced data pre-processing** :  \n",
    "- Fine-grained Tokenization: In this assignment, we just tokenize the iuput contexts by blank space, while a fine-grained tokenization may capture the nuances of the language better. This could include handling idiomatic phrases or subword-level tokens (e.g., BPE) more effectively.\n",
    "- Balancing distribution: Here we noticed that the distribution of word senses is imbalanced, which possibly influence the WSD models' performance. Statistical sampling methods like Bootstrap may be helpful to improve the quality of data.  \n",
    "- Noise Reduction: We could also clean the data to remove noise, such as irrelevant tokens or misspellings, that could confuse the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readings\n",
    "\n",
    "[1] Kågebäck, M., & Salomonsson, H. (2016). Word Sense Disambiguation using a Bidirectional LSTM. arXiv preprint arXiv:1606.03568.\n",
    "\n",
    "[2] ON WSD: https://web.stanford.edu/~jurafsky/slp3/slides/Chapter18.wsd.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statement of contribution\n",
    "\n",
    "Briefly state how many times you have met for discussions, who was present, to what degree each member contributed to the discussion and the final answers you are submitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marks\n",
    "\n",
    "This assignment has a total of 46 marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
